---
title: Tools, Demos & Resources
layout: resources
description: 'List of resource outputs produced by our group'
image: assets/images/illustration-tools-resources.jpg
nav-menu: true
---

## In addition to resources available from our [GitHub](https://github.com/wlv-rgcl), a list of resources is available below, organised by categories:

<p>
<a href="#core_nlp">Core NLP</a><br />
<a href="#core_nlp_util">Core NLP (utility)</a><br />
<a href="#LP4AT">Language Processing for Assistive Technologies</a><br />
<a href="#lexicography">Lexicography (Applied NLP)</a><br />
<a href="#nlp_socialmedia">NLP for Social Media</a><br />
<a href="#nlp_learning">NLP for Technology-Enhanced Learning</a><br />
<a href="#tech_learning">Technology-Enhanced Learning</a><br />
<a href="#transl8tech">Translation Technologies</a><br />
</p>



<h2 id="core_nlp">&#8212; Core NLP &#8212; </h2>



<h3>Datasets</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><th>Resource</th><th>Contact person</th><th>Description</th><th>Language(s)</th></tr><tr><td><a href="https://github.com/shivaat/itVN"><strong>itVN</strong></a></td><td>Shiva Taslimipoor<br /><a href="mailto:&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Concordances of Verb+Noun Multiword Expressions (MWEs)</td><td>Italian</td></tr><tr><td><a href="https://github.com/in6087/OB1/tree/master/corpora"><strong>Signs corpus</strong></a></td><td>Richard Evans<br /><a href="mailto:&#x72;&#x2e;&#x6a;&#x2e;&#x65;&#x76;&#x61;&#x6e;&#x73;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x72;&#x2e;&#x6a;&#x2e;&#x65;&#x76;&#x61;&#x6e;&#x73;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Corpus annotated with information about lexical and punctuational markers of syntactic complexity. Corpus used to train shallow syntactic analysers (sign tagger).</td><td>English</td></tr><tr><td><a href="https://github.com/shivaat/mwe-geco"><strong>mwe-geco</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Extracted files from the GECO eye-tracking corpus annotated with Verb-Noun and Verb-Particle constructions.</td><td>English</td></tr><tr><td><a href="https://github.com/in6087/STARS/tree/master/sequences"><strong>STARS corpus</strong></a></td><td>Richard Evans<br /><a href="mailto:&#x72;&#x2e;&#x6a;&#x2e;&#x65;&#x76;&#x61;&#x6e;&#x73;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x72;&#x2e;&#x6a;&#x2e;&#x65;&#x76;&#x61;&#x6e;&#x73;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Token sequences labelled with information about compound constituents and complex constituents. Dataset used to train partial parsers</td><td>English</td></tr></tbody></table></figure>



<h3>NLP Tools</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="http://www.lexytrad.es/en/resources/recor-3/"><strong>ReCor</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>ReCor is an effective solution to determine the minimum size of a corpus or a textual collection, regardless of language or textual genre of the collection, establishing therefore the minimum threshold for representation by an algorithm (N-Cor) and analysing lexical density according to the incremental increase in the corpus.</td><td>Language independent</td></tr><tr><td><a href="http://www.lexytrad.es/en/resources/inteliterm/"><strong>INTELITERM</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Inteliterm is an intelligent multilingual dictionary designed in Java and related to the health and beauty tourism sector. It allows to quickly display the information of the selected terms which are included in the Interliterm database. It also has a TBX database management module and it is linked to a corpus manager that allows searching for concordances, n-grams, etc.</td><td>Language independent</td></tr><tr><td><a href="http://www.lexytrad.es/en/resources/ontodiccionario/"><strong>OntoDiccionario</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>OntoDiccionario is a software application capable of displaying the conceptual and terminological information implemented in a RDF/OWL ontology (created by means of the program TopBraid Composer); it allows the users to search for terms and to navigate through concepts by means of hyperlinks. The application is based on the idea of taking the ontology code and parsing its content, in such a way that all classes, relations, properties and labels are captured; these data are then represented on a simple user interface, which includes a list of concepts, search engine, and a display window that shows the data for each concept.</td><td>Language independent</td></tr><tr><td><a href="https://github.com/omidrohanian/gappy-mwes"><strong>Gappy MWEs</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Bridging the Gap: Attending to Discontinuity in Identification of Multiword Expressions. Code to identify MWEs whicb contain gaps?</td><td>English, French, German, Persian</td></tr><tr><td><a href="https://github.com/kunilovskaya/UDsyntax"><strong>UDsyntax</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Calculates -percentage of non-projective dependencies in a treebank (or any .conllu) to all dependencies -percentage of sentences (=trees) with such dependencies</td><td>Language independent</td></tr><tr><td><a href="https://github.com/shivaat/VMWE-Identification"><strong>VMWE Identification</strong></a></td><td>Shiva Taslimipoor<br /><a href="mailto:&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code and documentation for &#8220;automatic identification of verbal multiword expressions&#8221;</td><td></td></tr><tr><td><a href="https://github.com/shivaat/discriminative_attribute"><strong>discriminative_attribute</strong></a></td><td>Shiva Taslimipoor<br /><a href="mailto:&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code and documentation for &#8220;Capturing Discriminative Attributes&#8221;</td><td></td></tr><tr><td><a href="https://github.com/shivaat/discriminative_attribute"><strong>Finding Discriminative Attributes</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code and documentation for the SemEval 2018 shared task Capturing Discriminative Attributes. a classification system to determine whether an attribute word can distinguish one word from another.</td><td>English</td></tr><tr><td><a href="https://github.com/kunilovskaya/corpusometry"><strong>corpusometry</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Data and code related to the task of creating homogeneous and functionally similar subsets of two arbitrary text collections</td><td>Language independent</td></tr><tr><td><a href="https://github.com/omidrohanian/metaphor_mwe"><strong>Model for metaphor classification informed by detection of multiword units</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Model for metaphor classification informed by detection of multiword units</td><td>English</td></tr><tr><td><a href="https://github.com/kunilovskaya/dms"><strong>dms</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Scripts and support files for processing/extracting statistics/visualising learners tmx and professional tmx (and reference (txt) corpora with regard to discourse markers analysis</td><td>Language independent</td></tr><tr><td><a href="https://github.com/zeeshansayyed/ArabicSOS"><strong>Arabic SOS</strong></a></td><td>Emad Mohamed<br /><a href="mailto:&#x45;&#x2e;&#x4d;&#x6f;&#x68;&#x61;&#x6d;&#x65;&#x64;&#x32;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x45;&#x2e;&#x4d;&#x6f;&#x68;&#x61;&#x6d;&#x65;&#x64;&#x32;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Segmenter and Orthography Standardazier (SOS) for Classical Arabic (CA)</td><td></td></tr><tr><td><a href="https://github.com/tharindudr/Siamese-Recurrent-Architectures"><strong>Siamese-Recurrent-Architectures</strong></a></td><td>Tharindu D. Ranasinghe Hettiarachchige<br /><a href="mailto:&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Siamese neural networks for semantic textual similarity.</td><td>Language independent</td></tr><tr><td><a href="https://github.com/shivaat/VMWE-Identification"><strong>VMWE-Identification</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Tagging verbal multiword expressions</td><td>English, Spanish</td></tr><tr><td><a href="https://github.com/kunilovskaya/hypohyper"><strong>hypohyper</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>taxonomy enrichment for russian</td><td>Russian</td></tr><tr><td><a href="https://github.com/kunilovskaya/bilm-tf"><strong>bilm-tf</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Tensorflow implementation of the pretrained biLM used to compute ELMo representations from &#8220;Deep contextualized word representations&#8221;.</td><td>Language independent</td></tr><tr><td><a href="https://github.com/omidrohanian/gaze-mwe-ranlp2017"><strong>Prediction of multiword expressions using eye tracking data</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>This repository contains the source code, data, and analyses behind the paper Using Gaze Data to Predict Multiword Expressions.</td><td>English</td></tr><tr><td><a href="https://github.com/tharindudr/Simple-Sentence-Similarity"><strong>Simple-Sentence-Similarity</strong></a></td><td>Tharindu D. Ranasinghe Hettiarachchige<br /><a href="mailto:&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Unsupervised methods to calculate the semantic textual similarity</td><td>Language independent</td></tr><tr><td><a href="https://github.com/kunilovskaya/webvectors"><strong>webvectors</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Web-ify your word2vec: framework to serve distributional semantic models online</td><td>Language independent</td></tr><tr><td><a href="https://github.com/victoria-ianeva/It-Classification"><strong>Classifying Referential and Non-referential It Using Gaze (includes data)</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>This repository contains code, annotation and data for the study on classifying referential and non-referential it using gaze:</td><td>English</td></tr><tr><td><a href="http://rgcl.wlv.ac.uk/demos/SignTaggerWebDemo/"><strong>Sign tagger (web demo)</strong></a></td><td>Richard Evans<br /><a href="mailto:&#x72;&#x2e;&#x6a;&#x2e;&#x65;&#x76;&#x61;&#x6e;&#x73;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x72;&#x2e;&#x6a;&#x2e;&#x65;&#x76;&#x61;&#x6e;&#x73;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Shallow syntactic analysis</td><td>English</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>


<h2 id="core_nlp_util">&#8212; Core NLP (utility) &#8212;</h2>



<h3>NLP Tools</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="http://www.lexytrad.es/en/resources/scleaner/"><strong>Scleaner</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>SCleaner is a program that helps users to format text copied from a pdf file. When copying and pasting from a PDF file, users can find various formatting problems: white spaces, tabulations, sentence boundaries, etc. Scleaner removes extra tabs and white spaces, and splits sentences in the right place automatically.</td><td>Language independent</td></tr></tbody></table></figure>



<h2 id="LP4AT">&#8212; Language Processing for Assistive Technologies &#8212; </h2>



<h3>Datasets</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="https://github.com/victoria-ianeva/Gaze-Data-from-Web-Searching-Tasks"><strong>Gaze data from participants with and without autism completing web searching tasks</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Contains gaze data from participants with and without autism completing web searching tasks</td><td>English</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>


<h2 id="lexicography">&#8212; Lexicography (Applied NLP) &#8212;</h2>



<h3>Datasets</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="http://pdev.org.uk/"><strong>PDEV</strong></a></td><td>Patrick Hanks<br /><a href="mailto:&#x70;&#x61;&#x74;&#x72;&#x69;&#x63;&#x6b;&#x2e;&#x77;&#x2e;&#x68;&#x61;&#x6e;&#x6b;&#x73;&#x40;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;">&#x70;&#x61;&#x74;&#x72;&#x69;&#x63;&#x6b;&#x2e;&#x77;&#x2e;&#x68;&#x61;&#x6e;&#x6b;&#x73;&#x40;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;</a></td><td>Corpus-driven dictionary of English verb patterns</td><td>English</td></tr><tr><td><a href="http://pdev.org.uk/"><strong>PDEV</strong></a></td><td>Sara Moze<br /><a href="mailto:&#x53;&#x2e;&#x4d;&#x6f;&#x7a;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x53;&#x2e;&#x4d;&#x6f;&#x7a;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Corpus-driven dictionary of English verb patterns</td><td>English</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>


<h2 id="nlp_socialmedia">&#8212; NLP for Social Media &#8212;</h2>



<h3>Datasets</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="https://sites.google.com/site/offensevalsharedtask/olid"><strong>Offensive Language Identification Dataset (OLID)</strong></a></td><td>Marcos Zampieri<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x63;&#x6f;&#x73;&#x2e;&#x7a;&#x61;&#x6d;&#x70;&#x69;&#x65;&#x72;&#x69;&#x40;&#x72;&#x69;&#x74;&#x2e;&#x65;&#x64;&#x75;">&#x6d;&#x61;&#x72;&#x63;&#x6f;&#x73;&#x2e;&#x7a;&#x61;&#x6d;&#x70;&#x69;&#x65;&#x72;&#x69;&#x40;&#x72;&#x69;&#x74;&#x2e;&#x65;&#x64;&#x75;</a></td><td>A collection of 14,200 annotated English tweets using an annotation model that encompasses following three levels: A: Offensive Language DetectionB: Categorization of Offensive LanguageC: Offensive Language Target Identification</td><td>English</td></tr><tr><td><a href="https://zpitenis.com/resources/ogtd/"><strong>Greek Dataset for Offensive Language Identification</strong></a></td><td>Tharindu D. Ranasinghe Hettiarachchige<br /><a href="mailto:&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Offensive Language Identification</td><td>Greek</td></tr></tbody></table></figure>



<h3>NLP Tools</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="https://github.com/omidrohanian/irony_detection"><strong>Irony Detection</strong></a></td><td>Shiva Taslimipoor<br /><a href="mailto:&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code and documentation for &#8220;WLV at SemEval-2018 Task 3&#8221;</td><td></td></tr><tr><td><a href="https://github.com/tharindudr/DeepOffense"><strong>DeepOffense</strong></a></td><td>Tharindu D. Ranasinghe Hettiarachchige<br /><a href="mailto:&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Multilingual Offensive Language Identification with Cross-lingual Embeddings</td><td>Bengali, English, Hindi, Spanish</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>


<h2 id="nlp_learning">&#8212; NLP for Technology-Enhanced Learning &#8212;</h2>



<h3>NLP Tools</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="https://github.com/victoria-ianeva/QA-for-medical-MCQs"><strong>QA-for-medical-MCQs (includes data)</strong></a></td><td>Le An Ha<br /><a href="mailto:&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x68;&#x61;&#x2e;&#x6c;&#x2e;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>This repository contains the python code and public data set for</td><td>English</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>


<h2 id="tech_learning">&#8212; Technology-Enhanced Learning &#8212;</h2>



<h3>Datasets</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Tell-Me</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Comparable corpus of medical texts</td><td>English, German, Spanish</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>


<h2 id="transl8tech">&#8212; Translation Technologies &#8212;</h2>



<h3>Datasets</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="https://www.rus-ltc.org/static/html/about.html"><strong>Russian Learner Translator Corpus (RusLTC)</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Bi-directional multiple corpus, which stores English-Russian translations done by university translation students</td><td>English, Russian</td></tr><tr><td><a href="https://github.com/shivaat/EnEsCC"><strong>EnEsCC</strong></a></td><td>Shiva Taslimipoor<br /><a href="mailto:&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x73;&#x74;&#x37;&#x39;&#x37;&#x40;&#x63;&#x61;&#x6d;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>English Spanish Comparable Corpora</td><td>_</td></tr><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Ecoturismo</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Comparable corpus of tourism texts</td><td>English, Spanish</td></tr><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Inteliterm (Comparable)</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Comparable corpus of health, beauty, and tourism texts</td><td>English, German, Italian, Spanish</td></tr><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Inteliterm (Parallel)</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Parallel corpus of health, beauty, and tourism texts</td><td>English, German, Italian, Spanish</td></tr><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Termitur (Comparable)</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Comparable corpus of tourism texts</td><td>English, German, Spanish</td></tr><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Termitur (Parallel)</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Comparable corpus of tourism texts</td><td>English, German, Spanish</td></tr><tr><td><a href="http://lexytrad.es/tradicor/app/"><strong>Turicor</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Comparable corpus of tourism/maritime transport texts</td><td>English, French, German, Spanish</td></tr></tbody></table></figure>



<h3>NLP Tools</h3>



<figure class="wp-block-table is-style-stripes"><table><tbody><tr><td><a href="http://www.lexytrad.es/termitur/termitur.php"><strong>TERMITUR</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Termitur is a lexicographic multilingual system oriented to the tourism sector. Termitur is a proposal of intelligent specialised dictionary based on documents and digital resources related to tourism 2.0 that is combined with intelligent terminology management systems and (semi)automatic corpus complication. It uses corpus previously compiled by the research team on rural and nature tourism and health and beauty tourism, as well as other corpus compiled in a (semi)automatic way. The result is a hybrid system that allows the translator and the interpreter to acquire specialised knowledge of the tourism sector in German, English and Spanish, as well as the resulting language pairs.</td><td>English, German, Spanish</td></tr><tr><td><a href="http://www.lexytrad.es/en/resources/trandix/"><strong>Trandix</strong></a></td><td>Gloria Corpas<br /><a href="mailto:&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;">&#x67;&#x63;&#x6f;&#x72;&#x70;&#x61;&#x73;&#x40;&#x75;&#x6d;&#x61;&#x2e;&#x65;&#x73;</a></td><td>Trandix is a computer application that aims to assist the translator during the process of decoding and encoding messages. It improves consultation of terminological information which the translator may need through a fast and convenient way. This application also allows users to upload TBX files without size limit. Those files could be exported from a terminology database of any kind of specialty.</td><td>Language independent</td></tr><tr><td><a href="https://github.com/kunilovskaya/fluency"><strong>fluency</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>An attempt to capture fluency as an aspect of translation quality along with accuracy</td><td>English, Russian</td></tr><tr><td><a href="https://github.com/kunilovskaya/HiT-IT"><strong>HiT-IT</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code and data related to translationese-for-quality project, presented at HiT-IT</td><td>Language independent</td></tr><tr><td><a href="https://github.com/kunilovskaya/parcorp"><strong>parcorp</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code to create a register balance corpus for translationese studies</td><td>Language independent</td></tr><tr><td><a href="https://github.com/kunilovskaya/translationese45"><strong>translationese45</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Code to extract 45 translationese indicators for English, German and Russian, most of which were used in the research presented at LREC 2020</td><td>English, German, Russian</td></tr><tr><td><a href="https://github.com/kunilovskaya/scrape"><strong>scrape</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Tool to collect parallel texts from the web</td><td>Language independent</td></tr><tr><td><a href="https://github.com/tharindudr/Intelligent-Translation-Memories"><strong>Intelligent-Translation-Memories</strong></a></td><td>Tharindu D. Ranasinghe Hettiarachchige<br /><a href="mailto:&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Semantically powerful translation memory matching and retrieval</td><td>Language independent</td></tr><tr><td><a href="https://github.com/tharindudr/TransQuest"><strong>TransQuest</strong></a></td><td>Tharindu D. Ranasinghe Hettiarachchige<br /><a href="mailto:&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x74;&#x2e;&#x64;&#x2e;&#x72;&#x61;&#x6e;&#x61;&#x73;&#x69;&#x6e;&#x67;&#x68;&#x65;&#x68;&#x65;&#x74;&#x74;&#x69;&#x61;&#x72;&#x61;&#x63;&#x68;&#x63;&#x68;&#x69;&#x67;&#x65;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Translation Quality Estimation with Cross-lingual Transformers.</td><td>Language independent</td></tr><tr><td><a href="https://github.com/kunilovskaya/accuracy"><strong>accuracy</strong></a></td><td>Maria Kunilovskaya<br /><a href="mailto:&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;">&#x6d;&#x61;&#x72;&#x69;&#x61;&#x2e;&#x6b;&#x75;&#x6e;&#x69;&#x6c;&#x6f;&#x76;&#x73;&#x6b;&#x61;&#x79;&#x61;&#x40;&#x77;&#x6c;&#x76;&#x2e;&#x61;&#x63;&#x2e;&#x75;&#x6b;</a></td><td>Tool using cross-linguistic text similarity to capture accuracy</td><td>English, Russian</td></tr></tbody></table></figure>


<p><a href="#top">Back to top of page</a></p>
