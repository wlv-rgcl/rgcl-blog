---
layout: seminar
title: "Automatic Speech Transcription and Translation in the Classroom and Lecture Setting: The Technologies, How They’re Being Used, and Where We’re Going"
speaker: "William Lewis"
affiliation: "University of Washington and Microsoft Translator"
time: 4pm
series: emtti # emtti, nlp, mldl, dh 
image: null 
---

### Abstract

We have witnessed significant progress in Automated Speech Recognition (ASR) and Machine Translation (MT) in recent years, so much so that Speech Translation, itself a combination of these underlying technologies, is becoming a viable technology in its own right. Although not perfect, many have called what they’ve seen of the current technology the “Universal Translator” or the “mini-UN on a phone”. But we’re not done and there are many problems to solve. For example, for Speech Translation to work well, it is not sufficient to stitch together the two underlying technologies of ASR and MT and call it done. People are amazingly disfluent, which can have profound negative impacts on transcripts and translations. We need to make the output of ASR more “fluent”; this has the effect of improving the quality of downstream translations. Further, since “fluent” output is much more readable and “caption-like” than disfluent, it is also more easily consumable by same-language users. This opens doors to broader accessibility scenarios. Speech Translation is currently being used in a variety of scenarios, no more so than in education. It sees its greatest uptake in settings where one or more speakers needs to communicate with a multilingual population. Perfect examples are the classroom, but we also see its use in parent-teacher conferences. The underlying technologies can be enhanced further by giving users some control over customizing the underlying models, e.g., to domain-specific vocabulary or speaker accents, significantly improving user experiences. In this talk I will demonstrate the technology in action as part of the presentation.

### Speaker's bio

Dr. William Lewis is an Affiliate Assistant Professor at the University of Washington, and until recently, a Principal PM Architect with the Microsoft Translator team.  He has led the Microsoft Translator team's efforts to build Machine Translation engines for a variety of the world's languages, including threatened and endangered languages, and has been working with the Translator team on Speech Translation.  He has been leading the efforts to support the features that allow students to use Microsoft Translator in the classroom, both for multilingual and deaf and hard of hearing audiences. 
 
Before joining Microsoft, Will was Assistant Professor and founding faculty for the Computational Linguistics Master's Program at the University of Washington. Before that, he was faculty at CSU Fresno, where he helped found the Computational Linguistic and Cognitive Science Programs at the university. 
 
He received a Bachelor's degree in Linguistics from the University of California Davis and a Master's and Doctorate in Linguistics, with an emphasis in Computational Linguistics, from the University of Arizona in Tucson. In addition to regularly publishing in the fields of Natural Language Processing and Machine Translation, Will is on the editorial board for the Journal of Machine Translation, has previously served on the board for the Association for Machine Translation in the Americas (AMTA), served as a program chair for the National American Association for Computational Linguistics (NAACL) conference, served as a program chair for the Machine Translation Summit, regularly reviews papers for a number of Computational Linguistic conferences, and has served multiple times as a panelist for the National Science Foundation.

